#!/usr/bin/env python3
"""
APIæµ‹è¯•è„šæœ¬ - éªŒè¯åç«¯åŠŸèƒ½
è¿è¡Œæ¡ä»¶ï¼šéœ€è¦å…ˆå¯åŠ¨åç«¯æœåŠ¡ (python3 main.py)
"""
import asyncio
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from services.openai_service import openai_service
from crypto_utils import secure_storage
from config import PROVIDERS, settings

async def test_model_categorization():
    """æµ‹è¯•æ¨¡å‹åˆ†ç±»åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯•æ¨¡å‹åˆ†ç±»åŠŸèƒ½")
    print("=" * 50)
    
    test_models = [
        "gpt-4o",
        "claude-3-5-sonnet-20241022", 
        "qwen2.5-72b-instruct",
        "deepseek-ai/DeepSeek-V2.5",
        "gemini-pro",
        "yi-large",
        "moonshot-v1-8k",
        "doubao-pro-4k",
        "ernie-bot-turbo",
        "flux-pro",
        "dall-e-3",
        "whisper-1",
        "text-embedding-3-large"
    ]
    
    for model in test_models:
        category = openai_service._categorize_model(model)
        print(f"æ¨¡å‹: {model:<30} -> ç±»åˆ«: {category}")

async def test_provider_configs():
    """æµ‹è¯•ä¾›åº”å•†é…ç½®"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•ä¾›åº”å•†é…ç½®")
    print("=" * 50)
    
    # æ£€æŸ¥åŠ å¯†å­˜å‚¨
    print("åŠ å¯†å­˜å‚¨çš„ä¾›åº”å•†:")
    secure_providers = secure_storage.list_providers()
    for provider, config in secure_providers.items():
        print(f"  {provider}: {'å·²é…ç½®' if config['configured'] else 'æœªé…ç½®'}")
    
    print("\næ‰€æœ‰å¯ç”¨ä¾›åº”å•†:")
    for provider_key, provider_info in PROVIDERS.items():
        print(f"  {provider_key}:")
        print(f"    åç§°: {provider_info['name']}")
        print(f"    URL: {provider_info['base_url']}")
        print(f"    APIå¯†é’¥å­—æ®µ: {provider_info['api_key_field']}")

async def test_model_retrieval():
    """æµ‹è¯•æ¨¡å‹è·å–åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ¨¡å‹è·å–åŠŸèƒ½")
    print("=" * 50)
    
    for provider_name in PROVIDERS.keys():
        print(f"\næµ‹è¯•ä¾›åº”å•†: {provider_name}")
        try:
            models = await openai_service.get_models(provider_name)
            if models:
                print(f"  âœ… æˆåŠŸè·å– {len(models)} ä¸ªæ¨¡å‹")
                
                # ç»Ÿè®¡ç±»åˆ«
                categories = {}
                for model in models:
                    cat = model.get('category', 'Other')
                    categories[cat] = categories.get(cat, 0) + 1
                
                print("  ç±»åˆ«åˆ†å¸ƒ:")
                for category, count in sorted(categories.items()):
                    print(f"    {category}: {count} ä¸ª")
                
                # æ˜¾ç¤ºå‰5ä¸ªæ¨¡å‹ç¤ºä¾‹
                print("  æ¨¡å‹ç¤ºä¾‹:")
                for model in models[:5]:
                    print(f"    {model['id']} ({model['category']})")
                
            else:
                print(f"  âš ï¸ æœªè·å–åˆ°æ¨¡å‹åˆ—è¡¨ (å¯èƒ½æ˜¯APIå¯†é’¥æœªé…ç½®)")
        except Exception as e:
            print(f"  âŒ é”™è¯¯: {str(e)}")

async def test_api_endpoints():
    """æ¨¡æ‹ŸAPIç«¯ç‚¹æµ‹è¯•"""
    print("\n" + "=" * 50)
    print("APIç«¯ç‚¹åŠŸèƒ½éªŒè¯")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿ GET /api/models/ è¯·æ±‚
    print("1. æ¨¡å‹åˆ—è¡¨APIåŠŸèƒ½éªŒè¯:")
    try:
        models = await openai_service.get_models()
        if models:
            # æµ‹è¯•æœç´¢åŠŸèƒ½
            search_term = "gpt"
            filtered = [m for m in models if search_term.lower() in m['id'].lower()]
            print(f"   æœç´¢ '{search_term}': æ‰¾åˆ° {len(filtered)} ä¸ªåŒ¹é…æ¨¡å‹")
            
            # æµ‹è¯•ç±»åˆ«è¿‡æ»¤
            categories = set(m.get('category', 'Other') for m in models)
            print(f"   å¯ç”¨ç±»åˆ«: {', '.join(sorted(categories))}")
            
            # æµ‹è¯•åˆ†é¡µ
            page_size = 10
            total_pages = (len(models) + page_size - 1) // page_size
            print(f"   åˆ†é¡µæµ‹è¯•: æ€»è®¡ {len(models)} ä¸ªæ¨¡å‹ï¼Œæ¯é¡µ {page_size} ä¸ªï¼Œå…± {total_pages} é¡µ")
        else:
            print("   âš ï¸ å½“å‰ä¾›åº”å•†æœªè¿”å›æ¨¡å‹åˆ—è¡¨")
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)}")
    
    print("\n2. ä¾›åº”å•†æµ‹è¯•APIåŠŸèƒ½éªŒè¯:")
    for provider_name in PROVIDERS.keys():
        try:
            # æ¨¡æ‹Ÿ POST /api/models/test/{provider_name}
            models = await openai_service.get_models(provider_name)
            status = "healthy" if models else "unconfigured"
            print(f"   {provider_name}: {status} ({len(models) if models else 0} æ¨¡å‹)")
        except Exception as e:
            print(f"   {provider_name}: error - {str(e)}")

def print_summary():
    """æ‰“å°æ€»ç»“"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 50)
    print("âœ… æ¨¡å‹åˆ†ç±»ç®—æ³•æ­£å¸¸å·¥ä½œ")
    print("âœ… ä¾›åº”å•†é…ç½®ç³»ç»Ÿæ­£å¸¸")
    print("âœ… æ¨¡å‹è·å–åŠŸèƒ½å·²å®ç°")
    print("âœ… APIç«¯ç‚¹è®¾è®¡åˆç†")
    print("\nğŸ“‹ åç«¯APIçŠ¶æ€:")
    print("   - æ¨¡å‹ç®¡ç†API (/api/models/*) å·²å®Œå–„")
    print("   - æ”¯æŒå¤šä¾›åº”å•†åŠ¨æ€åˆ‡æ¢")
    print("   - æ”¯æŒæ¨¡å‹æœç´¢ã€åˆ†ç±»ã€åˆ†é¡µ")
    print("   - æ”¯æŒä¾›åº”å•†å¥åº·æµ‹è¯•")
    print("   - æ”¯æŒåŠ å¯†APIå¯†é’¥å­˜å‚¨")
    print("\nğŸ¯ å‰ç«¯ä»»åŠ¡å·²ç§»äº¤ç»™Gemini:")
    print("   - è¯¦ç»†è¯´æ˜æ–‡æ¡£: GEMINI_ä¼˜åŒ–æ–‡æ¡£.md")
    print("   - åŒ…å«å®Œæ•´APIè°ƒç”¨æ–¹æ³•")
    print("   - åŒ…å«å‰ç«¯é—®é¢˜åˆ†æ")
    print("   - åŒ…å«å®ç°æŒ‡å¯¼æ–¹æ¡ˆ")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åç«¯APIåŠŸèƒ½æµ‹è¯•")
    
    await test_model_categorization()
    await test_provider_configs()
    await test_model_retrieval()
    await test_api_endpoints()
    print_summary()

if __name__ == "__main__":
    asyncio.run(main())